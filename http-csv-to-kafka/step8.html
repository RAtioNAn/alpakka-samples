<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
<title>Step 8: Scheduled download &bull; Alpakka step-by-step example</title>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<meta name="description" content="Alpakka Samples"/>
<script type="text/javascript" src="lib/jquery/jquery.min.js"></script>
<script type="text/javascript" src="lib/foundation/dist/js/foundation.min.js"></script>
<link rel="stylesheet" type="text/css" href="lib/normalize.css/normalize.css"/>
<link rel="stylesheet" type="text/css" href="lib/foundation/dist/css/foundation.min.css"/>
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/docsearch.js/2/docsearch.min.css" />
<link rel="stylesheet" type="text/css" href="css/icons.css"/>
<link rel="stylesheet" type="text/css" href="css/page.css"/>
<link rel="shortcut icon" href="images/favicon.ico" />
<link rel="apple-touch-icon" sizes="180x180" href="images/apple-touch-icon.png"/>
<link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32x32.png"/>
<link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png"/>
<link rel="manifest" href="images/manifest.json"/>
<meta name="msapplication-TileImage" content="images/mstile-150x150.png"/>
<meta name="msapplication-TileColor" content="#15a9ce"/>
<meta name="theme-color" content="#15a9ce"/>
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>
<!-- OneTrust Cookies Consent Notice (Production Standard, akka.io, en-GB) start -->
<script src="https://optanon.blob.core.windows.net/consent/159bb13d-6748-4399-806e-ac28db879785.js" type="text/javascript" charset="UTF-8"></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice (Production Standard, akka.io, en-GB) end -->
<!--Google Analytics-->
<script type="text/plain" class="optanon-category-2">
var _gaq = _gaq || [];
_gaq.push(['_setAccount', '']);
_gaq.push(['_setDomainName', '']);
_gaq.push(['_trackPageview']);
(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})()
</script>
<script type="text/plain" class="optanon-category-2">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-23127719-1', 'lightbend.com', {'allowLinker': true, 'name': 'tsTracker'});
ga('tsTracker.require', 'linker');
ga('tsTracker.linker:autoLink', ['lightbend.com','playframework.com','scala-lang.org','scaladays.org','spray.io','akka.io','scala-sbt.org','scala-ide.org']);
ga('tsTracker.send', 'pageview');
</script>
<!--Marketo-->
<script type="text/plain" class="optanon-category-3">
(function() {
var didInit = false;
function initMunchkin() {
if(didInit === false) {
didInit = true;
Munchkin.init('558-NCX-702', { 'asyncOnly': true, 'disableClickDelay': true });
}
}
var s = document.createElement('script');
s.type = 'text/javascript';
s.async = true;
s.src = '//munchkin.marketo.net/munchkin.js';
s.onreadystatechange = function() {
if (this.readyState == 'complete' || this.readyState == 'loaded') {
initMunchkin();
}
};
s.onload = initMunchkin;
document.getElementsByTagName('head')[0].appendChild(s);
})();
</script>
</head>

<body id="underlay" data-toggler="nav-open">

<header class="site-header hide-for-large">
<div class="sticky-header clearfix">
<a href="https://akka.io"><img class="logo" src="images/akka-logo-reverse.svg"/></a>

<button class="menu-icon float-right" type="button" data-toggle="underlay overlay"></button>
</div>
<div id="overlay" class="overlay-nav" data-toggler="nav-open">
<header class="nav-header">
<div class="nav-header-title">
<h1><a href="index.html">Alpakka step-by-step example</a></h1>
</div>
<div class="nav-header-version">
Version current
</div>
<div class="nav-header-groups">
<select class="supergroup" name="Language"><option class="group" value="group-java">Java</option><option class="group" value="group-scala">Scala</option></select>
</div>
</header>
<nav class="nav-toc">
<ul>
  <li><a href="index.html#fetch-csv-via-akka-http-and-publish-the-data-as-json-to-kafka" class="header">Fetch CSV via Akka HTTP and publish the data as JSON to Kafka</a></li>
  <li><a href="step1.html" class="page">Step 1: Send HTTP request</a></li>
  <li><a href="step2.html" class="page">Step 2: extract HTTP entity</a></li>
  <li><a href="step3.html" class="page">Step 3: parse CSV</a></li>
  <li><a href="step4.html" class="page">Step 4: Producing JSON</a></li>
  <li><a href="step5.html" class="page">Step 5: Cleanse lines from data source</a></li>
  <li><a href="step6.html" class="page">Step 6: Adding Coordinated Shutdown</a></li>
  <li><a href="step7.html" class="page">Step 7: Produce to Kafka</a></li>
  <li><a href="step8.html#step-8-scheduled-download" class="active page">Step 8: Scheduled download</a>
  <ul>
    <li><a href="step8.html#description" class="header">Description</a></li>
    <li><a href="step8.html#code" class="header">Code</a></li>
  </ul></li>
</ul>
</nav>
</div>
</header>

<aside class="show-for-large">
<header class="nav-header fixed-sidebar-header">
<div class="nav-header-title">
<h1><a href="index.html">Alpakka step-by-step example</a></h1>
</div>
<div class="nav-header-version">
Version current
</div>
<div class="nav-header-groups">
<select class="supergroup" name="Language"><option class="group" value="group-java">Java</option><option class="group" value="group-scala">Scala</option></select>
</div>
</header>
<nav class="site-nav fixed-sidebar-contents">
<div class="nav-toc">
<ul>
  <li><a href="index.html#fetch-csv-via-akka-http-and-publish-the-data-as-json-to-kafka" class="header">Fetch CSV via Akka HTTP and publish the data as JSON to Kafka</a></li>
  <li><a href="step1.html" class="page">Step 1: Send HTTP request</a></li>
  <li><a href="step2.html" class="page">Step 2: extract HTTP entity</a></li>
  <li><a href="step3.html" class="page">Step 3: parse CSV</a></li>
  <li><a href="step4.html" class="page">Step 4: Producing JSON</a></li>
  <li><a href="step5.html" class="page">Step 5: Cleanse lines from data source</a></li>
  <li><a href="step6.html" class="page">Step 6: Adding Coordinated Shutdown</a></li>
  <li><a href="step7.html" class="page">Step 7: Produce to Kafka</a></li>
  <li><a href="step8.html#step-8-scheduled-download" class="active page">Step 8: Scheduled download</a>
  <ul>
    <li><a href="step8.html#description" class="header">Description</a></li>
    <li><a href="step8.html#code" class="header">Code</a></li>
  </ul></li>
</ul>
</div>
</nav>
<footer class="nav-footer fixed-sidebar-footer">
<a href="https://akka.io"><img class="logo" src="images/akka-logo-reverse.svg"/></a>

</footer>
</aside>

<main class="fixed-shift-for-large expanded row">
<section class="site-content small-12 column">

<article class="page-content row">
<div class="small-12 large-9 column" id="docs">
<h1><a href="#step-8-scheduled-download" name="step-8-scheduled-download" class="anchor"><span class="anchor-link"></span></a>Step 8: Scheduled download</h1>
<h3><a href="#description" name="description" class="anchor"><span class="anchor-link"></span></a>Description</h3>
<p>Use <code>Source.tick</code> to run the HTTP request every 30 seconds. </p>
<p>Run the process for about a minute and stop the source after that.</p>
<h3><a href="#code" name="code" class="anchor"><span class="anchor-link"></span></a>Code</h3>
<dl>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-samples/tree/vcurrent/step_008_scheduled_download/src/main/java/samples/javadsl/Main.java" target="_blank" title="Go to snippet source"></a><code class="language-java">/*
 * Copyright (C) 2016-2019 Lightbend Inc. &lt;http://www.lightbend.com&gt;
 */

package samples.javadsl;

import akka.Done;
import akka.actor.ActorSystem;
import akka.actor.Cancellable;
import akka.actor.CoordinatedShutdown;
import akka.http.javadsl.Http;
import akka.http.javadsl.model.HttpRequest;
import akka.http.javadsl.model.HttpResponse;
import akka.http.javadsl.model.MediaRanges;
import akka.http.javadsl.model.StatusCodes;
import akka.http.javadsl.model.headers.Accept;
import akka.japi.Pair;
import akka.kafka.ConsumerSettings;
import akka.kafka.ProducerSettings;
import akka.kafka.Subscriptions;
import akka.kafka.javadsl.Consumer;
import akka.kafka.javadsl.Producer;
import akka.stream.ActorMaterializer;
import akka.stream.Materializer;
import akka.stream.alpakka.csv.javadsl.CsvParsing;
import akka.stream.alpakka.csv.javadsl.CsvToMap;
import akka.stream.javadsl.Keep;
import akka.stream.javadsl.Sink;
import akka.stream.javadsl.Source;
import akka.util.ByteString;
import com.fasterxml.jackson.core.JsonFactory;
import com.fasterxml.jackson.core.JsonGenerator;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;
import org.testcontainers.containers.KafkaContainer;

import java.io.IOException;
import java.io.StringWriter;
import java.time.Duration;
import java.util.Collections;
import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.CompletionStage;
import java.util.concurrent.TimeUnit;

public class Main {

    public static void main(String[] args) throws Exception {
        Main me = new Main();
        me.run();
    }

    final HttpRequest httpRequest =
            HttpRequest.create(
                    &quot;https://www.nasdaq.com/screening/companies-by-name.aspx?exchange=NASDAQ&amp;render=download&quot;)
                    .withHeaders(Collections.singletonList(Accept.create(MediaRanges.ALL_TEXT)));

    private Source&lt;ByteString, ?&gt; extractEntityData(HttpResponse httpResponse) {
        if (httpResponse.status() == StatusCodes.OK) {
            return httpResponse.entity().getDataBytes();
        } else {
            return Source.failed(new RuntimeException(&quot;illegal response &quot; + httpResponse));
        }
    }

    private Map&lt;String, String&gt; cleanseCsvData(Map&lt;String, ByteString&gt; map) {
        Map&lt;String, String&gt; out = new HashMap&lt;&gt;(map.size());
        map.forEach(
                (key, value) -&gt; {
                    if (!key.isEmpty()) out.put(key, value.utf8String());
                });
        return out;
    }

    private final JsonFactory jsonFactory = new JsonFactory();

    private String toJson(Map&lt;String, String&gt; map) throws Exception {
        StringWriter sw = new StringWriter();
        JsonGenerator generator = jsonFactory.createGenerator(sw);
        generator.writeStartObject();
        map.forEach(
                (key, value) -&gt; {
                    try {
                        generator.writeStringField(key, value);
                    } catch (IOException e) {
                        throw new RuntimeException(e);
                    }
                });
        generator.writeEndObject();
        generator.close();
        return sw.toString();
    }

    private void run() throws Exception {
        KafkaContainer kafkaBroker = new KafkaContainer();
        kafkaBroker.start();
        final String bootstrapServers = kafkaBroker.getBootstrapServers();

        ActorSystem system = ActorSystem.create();
        Materializer materializer = ActorMaterializer.create(system);
        Http http = Http.get(system);

        ProducerSettings&lt;String, String&gt; kafkaProducerSettings =
                ProducerSettings.create(system, new StringSerializer(), new StringSerializer())
                        .withBootstrapServers(bootstrapServers);

        Pair&lt;Cancellable, CompletionStage&lt;Done&gt;&gt; stagePair =
                Source.tick(
                        Duration.ofSeconds(1),
                        Duration.ofSeconds(30),
                        httpRequest) // : HttpRequest
                        .mapAsync(1, http::singleRequest) // : HttpResponse
                        .flatMapConcat(this::extractEntityData) // : ByteString
                        .via(CsvParsing.lineScanner()) // : List&lt;ByteString&gt;
                        .via(CsvToMap.toMap()) // : Map&lt;String, ByteString&gt;
                        .map(this::cleanseCsvData) // : Map&lt;String, String&gt;
                        .map(this::toJson) // : String
                        .map(elem -&gt;
                                new ProducerRecord&lt;String, String&gt;(
                                        &quot;topic1&quot;, elem) // : Kafka ProducerRecord
                        )
                        .toMat(Producer.plainSink(kafkaProducerSettings), Keep.both())
                        .run(materializer);

        CoordinatedShutdown cs = CoordinatedShutdown.get(system);
        cs.addTask(CoordinatedShutdown.PhaseActorSystemTerminate(), &quot;shut-down-client-http-pool&quot;, () -&gt;
                http.shutdownAllConnectionPools().thenApply(r -&gt; Done.done())
        );

        ConsumerSettings&lt;String, String&gt; kafkaConsumerSettings =
                ConsumerSettings.create(system, new StringDeserializer(), new StringDeserializer())
                        .withBootstrapServers(bootstrapServers)
                        .withGroupId(&quot;topic1&quot;)
                        .withProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;);

        Consumer.DrainingControl&lt;Done&gt; control =
                Consumer.atMostOnceSource(kafkaConsumerSettings, Subscriptions.topics(&quot;topic1&quot;))
                        .map(ConsumerRecord::value)
                        .toMat(Sink.foreach(System.out::println), Keep.both())
                        .mapMaterializedValue(Consumer::createDrainingControl)
                        .run(materializer);

        Cancellable tick = stagePair.first();
        CompletionStage&lt;Done&gt; streamCompletion = stagePair.second();

        TimeUnit.SECONDS.sleep(59);
        tick.cancel();

        streamCompletion
                .thenApplyAsync(done -&gt; control.drainAndShutdown(system.dispatcher()))
                .thenAccept(
                        done -&gt; {
                            kafkaBroker.stop();
                            cs.run(CoordinatedShutdown.unknownReason());
                        });
    }
}</code></pre></dd>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-samples/tree/vcurrent/step_008_scheduled_download/src/main/scala/samples/Main.scala" target="_blank" title="Go to snippet source"></a><code class="language-scala">/*
 * Copyright (C) 2016-2019 Lightbend Inc. &lt;http://www.lightbend.com&gt;
 */

package samples

import java.util.concurrent.TimeUnit

import akka.Done
import akka.actor._
import akka.stream._
import akka.http.scaladsl._
import akka.http.scaladsl.model.StatusCodes._
import akka.http.scaladsl.model.headers.Accept
import akka.http.scaladsl.model.{ HttpRequest, HttpResponse, MediaRanges }
import akka.kafka.scaladsl.{ Consumer, Producer }
import akka.kafka.{ ConsumerSettings, ProducerSettings, Subscriptions }
import akka.stream.alpakka.csv.scaladsl.{ CsvParsing, CsvToMap }
import akka.stream.scaladsl.{ Keep, Sink, Source }
import akka.util.ByteString
import org.apache.kafka.clients.consumer.ConsumerConfig
import org.apache.kafka.clients.producer.ProducerRecord
import org.apache.kafka.common.serialization.{ StringDeserializer, StringSerializer }
import org.testcontainers.containers.KafkaContainer
import spray.json.{ DefaultJsonProtocol, JsValue, JsonWriter }

import scala.concurrent.Future
import scala.concurrent.duration.DurationInt

object Main
  extends App
    with DefaultJsonProtocol {

  implicit val actorSystem = ActorSystem(&quot;alpakka-samples&quot;)

  import actorSystem.dispatcher

  implicit val mat: Materializer = ActorMaterializer()

  val httpRequest = HttpRequest(uri = &quot;https://www.nasdaq.com/screening/companies-by-name.aspx?exchange=NASDAQ&amp;render=download&quot;)
    .withHeaders(Accept(MediaRanges.`text/*`))

  def extractEntityData(response: HttpResponse): Source[ByteString, _] =
    response match {
      case HttpResponse(OK, _, entity, _) =&gt; entity.dataBytes
      case notOkResponse =&gt;
        Source.failed(new RuntimeException(s&quot;illegal response $notOkResponse&quot;))
    }

  def cleanseCsvData(csvData: Map[String, ByteString]): Map[String, String] =
    csvData
      .filterNot { case (key, _) =&gt; key.isEmpty }
      .mapValues(_.utf8String)

  def toJson(map: Map[String, String])(
    implicit jsWriter: JsonWriter[Map[String, String]]): JsValue = jsWriter.write(map)

  val kafkaBroker: KafkaContainer = new KafkaContainer()
  kafkaBroker.start()

  private val bootstrapServers: String = kafkaBroker.getBootstrapServers()

  val kafkaProducerSettings = ProducerSettings(actorSystem, new StringSerializer, new StringSerializer)
    .withBootstrapServers(bootstrapServers)

  val (ticks, future): (Cancellable, Future[Done]) =
    Source
      .tick(1.seconds, 7.seconds, httpRequest) //: HttpRequest
      .mapAsync(1)(Http().singleRequest(_)) //: HttpResponse
      .flatMapConcat(extractEntityData) //: ByteString
      .via(CsvParsing.lineScanner()) //: List[ByteString]
      .via(CsvToMap.toMap()) //: Map[String, ByteString]
      .map(cleanseCsvData) //: Map[String, String]
      .map(toJson) //: JsValue
      .map(_.compactPrint) //: String (JSON formatted)
      .map { elem =&gt;
        new ProducerRecord[String, String](&quot;topic1&quot;, elem) //: Kafka ProducerRecord
      }
      .toMat(Producer.plainSink(kafkaProducerSettings))(Keep.both)
      .run()

  val cs: CoordinatedShutdown = CoordinatedShutdown(actorSystem)
  cs.addTask(CoordinatedShutdown.PhaseServiceStop, &quot;shut-down-client-http-pool&quot;)( () =&gt;
    Http().shutdownAllConnectionPools().map(_ =&gt; Done)
  )

  val kafkaConsumerSettings = ConsumerSettings(actorSystem, new StringDeserializer, new StringDeserializer)
    .withBootstrapServers(bootstrapServers)
    .withGroupId(&quot;topic1&quot;)
    .withProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;)

  val control = Consumer
    .atMostOnceSource(kafkaConsumerSettings, Subscriptions.topics(&quot;topic1&quot;))
    .map(_.value)
    .toMat(Sink.foreach(println))(Keep.both)
    .mapMaterializedValue(Consumer.DrainingControl.apply)
    .run()

  TimeUnit.SECONDS.sleep(59)
  ticks.cancel()

  for {
    _ &lt;- future
    _ &lt;- control.drainAndShutdown()
  } {
    kafkaBroker.stop()
    cs.run(CoordinatedShutdown.UnknownReason)
  }
}</code></pre></dd>
</dl>
</div>
</article>

<div class="row">
<div class="small-12 large-9 column">
<section class="nav-prev-next row">
<div class="nav-prev small-6 column">
<a href="step7.html"><i class="icon-prev"></i> <span class="link-prev">Step 7: Produce to Kafka</span></a>
</div>
<div class="nav-next small-6 column clearfix">
</div>
</section>
</div>
</div>

<div class="source-github row">
Found an error in this documentation? The source code for this page can be found <a href="https://github.com/akka/alpakka-samples/tree/vcurrent/docs/src/main/paradox/step8.md">here</a>.
Please feel free to edit and contribute a pull request.
</div>


<footer class="page-footer row clearfix">
<img class="akka-icon float-left show-for-medium" src="images/akka-icon.svg"/>
<section class="copyright">
<div>Alpakka Samples is Open Source and available under the Apache 2 License.</div>
<p class="legal">
&copy; 2011-2019 <a href="https://www.lightbend.com" target="_blank">Lightbend, Inc.</a> | 
<a href="https://www.lightbend.com/legal/licenses" target="_blank">Licenses</a> | 
<a href="https://www.lightbend.com/legal/terms" target="_blank">Terms</a> | 
<a href="https://www.lightbend.com/legal/privacy" target="_blank">Privacy Policy</a> | 
<a href="https://akka.io/cookie/" target="_blank">Cookie Listing</a> | 
<a class="optanon-toggle-display">Cookie Settings</a>
</p>
</section>
</footer>

</section>
</main>

<script type="text/javascript" src="js/scrollsneak.js"></script>
<script type="text/javascript">jQuery(document).foundation();</script>
<script type="text/javascript" src="js/groups.js"></script>
<script type="text/javascript" src="js/page.js"></script>
<script type="text/javascript" src="js/magellan.js"></script>

<style type="text/css">@import "lib/prettify/prettify.css";</style>
<script type="text/javascript" src="lib/prettify/prettify.js"></script>
<script type="text/javascript" src="lib/prettify/lang-scala.js"></script>
<script type="text/javascript">//<![CDATA[
jQuery(function(){window.prettyPrint && prettyPrint()});
//]]></script>
<!-- hook for including project specific javascript into the generated docs -->

</body>
</html>
